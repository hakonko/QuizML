_question;_latex;_alt1;_alt2;_alt3;_alt4;_alt5;_correct_alt;_genre
In logistic regression for binary classification, what is the meaning/interpretation of the output of the sigmoid function for an input x?;;Estimate of parameters w;Cross-entropy loss value;Predicted probability Pr({y=1 | x});True label;Bias;_alt3;1
Which of the following options explains why convolutional neural networks became popular?;;Parameter sharing;Localized Pattern Detection;Hierarchical Pattern Recognition across Layers;All options;Pooling layers;_alt4;2
What is not an advantage of residual connection in deep neural networks?;;Identity+ optional non-linearity;Never worse than identity;If a convolution block is not useful, it will be bypassed;Visual info processed at various scales & concatenated along depth;Helps reduce the number of parameters in the network;_alt4;3
"A classification model is evaluated on 3 classes: A, B, and C. For each class, you are given the precision and recall values at each relevant threshold.The average precision (AP) is defined as the area under the precision-recall curve for each class.
Suppose we approximate this area using the 11-point interpolated Average Precision method, where precision is measured at 11 recall levels: {0.0, 0.1, 0.2, ..., 1.0}. For each recall level r, the precision is defined as the maximum precision obtained for any recall ≥ r.
You are given the following interpolated precision values:
Class A: [1.0, 1.0, 1.0, 0.9, 0.9, 0.85, 0.8, 0.7, 0.6, 0.5, 0.5]
Class B: [1.0, 1.0, 0.9, 0.9, 0.85, 0.8, 0.75, 0.7, 0.6, 0.6, 0.5]
Class C: [0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.6, 0.55, 0.5, 0.4]";mAP = \frac{1}{N} \sum_{i=1}^N AP_i,  \text{ where N is the number of classes};0.700;0.727;0.750;0.800;0.833;_alt3;4
A 1D convolutional layer has kernel size 3 and stride 2. A second layer on top uses kernel size 5 and stride 3. A third layer uses kernel size 3 and stride 1. How many input elements from the original input affect one output value of the third layer (assume no padding, center neuron)?;;15;11;17;21;13;_alt3;3
Which of the following is true about dropout?;;Dropout removes neurons during inference.;Dropout reduces training time significantly.;Dropout prevents co-adaptation and improves generalization.;Dropout increases the number of trainable parameters.;Dropout enforces weight sharing.;_alt3;2
Given a 3×2 input matrix and a transposed convolution with kernel size 2×2, stride 2, and no padding, what is the spatial size of the output?;\text{Output} = \text{Stride} \times (\text{Input size} - 1) + \text{Kernel size};6×4;5×3;7×5;4×2;3×2;_alt1;3
n a binary classification problem, we care more about detecting rare positive cases (label B). Which metric is most suitable?;;Accuracy;Specificity;Precision;Recall (Sensitivity);F1-score;_alt4;5
Given empirical risk minimization: How do you adjust it for importance weighting with known density ratios r(x,y)?;\min_{\theta} \frac{1}{N} \sum_{n=1}^N \ell(h_\theta(x_n), y_n);Multiply the loss by the predicted label;Add a penalty term based on class imbalanceReplace the loss with KL divergence;;Replace l with r(x_n, y_n)⋅l;Replace N with test set size;_alt4;5
A 2D convolution has input shape (112, 224), kernel size (5, 5), stride 4, and padding 5. What is the spatial output shape?;\text{Output size} = \left\lfloor \frac{N + 2P - K}{S} \right\rfloor + 1;(29, 57);(28, 56);(27, 55);(26, 54);(30, 58);_alt1;3
Why is stochastic gradient descent (SGD) often preferred over plain gradient descent (GD) for training deep networks?;;SGD always finds the global minimum;SGD uses less memory by removing the optimizer;SGD avoids vanishing gradients;SGD provides noisy gradients that help escape poor local minima;SGD automatically adjusts the learning rate;_alt4;2
In object detection, how do we assign predicted boxes to ground truth boxes during training?;;Based on pixel-wise accuracy;Using histogram equalization;Using Intersection over Union (IoU) threshold;By minimizing reconstruction loss;By matching identical coordinates;_alt3;6
Which combination best describes a targeted white-box attack?;;Attacker doesn’t know the model but can choose target class;Attacker knows model and tries to cause any misclassification;Attacker knows model and tries to classify as a specific wrong clas;Attacker has no access to gradients and perturbs randomly;Attacker uses PGD in a black-box setting;_alt3;7
You are building a segmentation model that must both segment the tumor region and assign a grade (1–4) per pixel. How many output channels should the final layer have?;;1;2;4;5;6;_alt4;8
You want to train a model to both classify and localize objects using bounding boxes. Which combination of losses is appropriate?;;Binary cross-entropy + Dice loss;Cross-entropy + L2 loss;Focal loss only;L1 loss only;IoU loss only;_alt2;5
Which of the following is a possible loss function for the generator in a GAN?;\min_G \log(1 - D(G(z)));Encourages discriminator to output 1;Encourages discriminator to output 0; Encourages generator to fool the discriminator;Maximizes likelihood of real data;Minimizes KL divergence;_alt3;9
What is the purpose of adding momentum to SGD?;;To increase learning rate over time;To reduce the batch size required;To compute second-order gradients;To avoid overfitting;To accelerate convergence and smooth oscillations;_alt5;2
How does the Vision Transformer (ViT) reduce the number of input tokens compared to using one token per pixel?;;Uses only every third pixel;Uses CNN for dimensionality reduction;Applies PCA before feeding to transformer;Divides the image into fixed-size patches and embeds them;Applies dropout to pixels;_alt4;6
An input image of size 64 x 64 is passed through two convolutional layers: Conv1: kernel size 5, stride 2, padding 2. Conv2: kernel size 3, stride 2, padding 1. What is the spatial output size after both layers?;;16 x 16 ;32 x 32;15 x 15 ;17 x 17;20 x 20;_alt1;3
A 2D convolutional layer has: 64 input channels, 128 output channels, kernel size 3x3, no bias terms. How many trainable parameters does it have?;;147,456;110,592;81,920;73,728;196,608;_alt1;3
Given gradient values g = (2, 4), previous EMA e = (1, 1), decay rate alpha = 0.9 and learning rate eta = 0.01, compute the RMSProp update step for the first component. Assume epsilon = 10^-8, and focus only on the first component.;e_t = \alpha \cdot e_{t-1} + (1 - \alpha) \cdot g^2 \\ \theta = \theta - \eta \cdot \frac{g}{\sqrt{e_t + \epsilon}};-0.0061;-0.0193;-0.0120;-0.0058;-0.0035;_alt4;2
An input of size 3 x 3 is passed through a transposed convolution with: kernel size 4, stride 2, padding 1. What is the spatial output size?;O = S \cdot (I - 1) + K - 2P;8 x 8;7 x 7;6 x 6;9 x 9;10 x 10;_alt1;3